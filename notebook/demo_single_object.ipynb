{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Copyright (c) Meta Platforms, Inc. and affiliates."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Imports and Model Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/dimi/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
                        "  import pynvml  # type: ignore[import]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Warp 1.10.1 initialized:\n",
                        "   CUDA Toolkit 12.8, Driver 12.1\n",
                        "   Devices:\n",
                        "     \"cpu\"      : \"x86_64\"\n",
                        "     \"cuda:0\"   : \"NVIDIA GeForce RTX 4080\" (16 GiB, sm_89, mempool enabled)\n",
                        "   Kernel cache:\n",
                        "     /home/dimi/.cache/warp/1.10.1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-20 18:20:21.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36mset_attention_backend\u001b[0m:\u001b[36m17\u001b[0m - \u001b[1mGPU name is NVIDIA GeForce RTX 4080\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
                        "[Open3D INFO] WebRTC GUI backend enabled.\n",
                        "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-20 18:20:23.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.sparse\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1m[SPARSE] Backend: spconv, Attention: sdpa\u001b[0m\n",
                        "\u001b[32m2025-12-20 18:20:25.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.model.backbone.tdfy_dit.modules.attention\u001b[0m:\u001b[36m__from_env\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1m[ATTENTION] Using backend: sdpa\u001b[0m\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[SPARSE][CONV] spconv algo: auto\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-20 18:20:26.388\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
                        "\u001b[32m2025-12-20 18:20:26.389\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import imageio\n",
                "import uuid\n",
                "from IPython.display import Image as ImageDisplay\n",
                "from inference import Inference, ready_gaussian_for_video_rendering, render_video, load_image, load_single_mask, display_image, make_scene, interactive_visualizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m2025-12-20 18:21:01.017\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4cd71d3098934c67a3cd2270ae1e3ab6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.pt:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/dimi/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/moge/model/v1.py:171: UserWarning: The following deprecated/invalid arguments are ignored: {'output_mask': True, 'split_head': True}\n",
                        "  warnings.warn(f\"The following deprecated/invalid arguments are ignored: {deprecated_kwargs}\")\n",
                        "\u001b[32m2025-12-20 18:21:16.849\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36msam3d_objects.data.dataset.tdfy.preprocessor\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m51\u001b[0m - \u001b[33m\u001b[1mNo rgb pointmap normalizer provided, using scale + shift \u001b[0m\n",
                        "\u001b[32m2025-12-20 18:21:16.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mself.device: cuda\u001b[0m\n",
                        "\u001b[32m2025-12-20 18:21:16.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mCUDA_VISIBLE_DEVICES: None\u001b[0m\n",
                        "\u001b[32m2025-12-20 18:21:16.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m102\u001b[0m - \u001b[1mActually using GPU: 0\u001b[0m\n",
                        "\u001b[32m2025-12-20 18:21:16.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36minit_pose_decoder\u001b[0m:\u001b[36m297\u001b[0m - \u001b[1mUsing pose decoder: ScaleShiftInvariant\u001b[0m\n",
                        "\u001b[32m2025-12-20 18:21:16.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msam3d_objects.pipeline.inference_pipeline\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m133\u001b[0m - \u001b[1mLoading model weights...\u001b[0m\n"
                    ]
                },
                {
                    "ename": "InstantiationException",
                    "evalue": "Error in call to target 'sam3d_objects.pipeline.inference_pipeline_pointmap.InferencePipelinePointMap':\nFileNotFoundError(2, 'No such file or directory')",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:92\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_target_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/sam-3d-objects/sam3d_objects/pipeline/inference_pipeline_pointmap.py:99\u001b[39m, in \u001b[36mInferencePipelinePointMap.__init__\u001b[39m\u001b[34m(self, depth_model, layout_post_optimization_method, clip_pointmap_beyond_scale, *args, **kwargs)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;28mself\u001b[39m.clip_pointmap_beyond_scale = clip_pointmap_beyond_scale\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/sam-3d-objects/sam3d_objects/pipeline/inference_pipeline.py:135\u001b[39m, in \u001b[36mInferencePipeline.__init__\u001b[39m\u001b[34m(self, ss_generator_config_path, ss_generator_ckpt_path, slat_generator_config_path, slat_generator_ckpt_path, ss_decoder_config_path, ss_decoder_ckpt_path, slat_decoder_gs_config_path, slat_decoder_gs_ckpt_path, slat_decoder_mesh_config_path, slat_decoder_mesh_ckpt_path, slat_decoder_gs_4_config_path, slat_decoder_gs_4_ckpt_path, ss_encoder_config_path, ss_encoder_ckpt_path, decode_formats, dtype, pad_size, version, device, ss_preprocessor, slat_preprocessor, ss_condition_input_mapping, slat_condition_input_mapping, pose_decoder_name, workspace_dir, downsample_ss_dist, ss_inference_steps, ss_rescale_t, ss_cfg_strength, ss_cfg_interval, ss_cfg_strength_pm, slat_inference_steps, slat_rescale_t, slat_cfg_strength, slat_cfg_interval, rendering_engine, shape_model_dtype, compile_model, slat_mean, slat_std)\u001b[39m\n\u001b[32m    133\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mLoading model weights...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m ss_generator = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minit_ss_generator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mss_generator_config_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss_generator_ckpt_path\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m slat_generator = \u001b[38;5;28mself\u001b[39m.init_slat_generator(\n\u001b[32m    139\u001b[39m     slat_generator_config_path, slat_generator_ckpt_path\n\u001b[32m    140\u001b[39m )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/sam-3d-objects/sam3d_objects/pipeline/inference_pipeline.py:307\u001b[39m, in \u001b[36mInferencePipeline.init_ss_generator\u001b[39m\u001b[34m(self, ss_generator_config_path, ss_generator_ckpt_path)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_ss_generator\u001b[39m(\u001b[38;5;28mself\u001b[39m, ss_generator_config_path, ss_generator_ckpt_path):\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     config = \u001b[43mOmegaConf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mworkspace_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss_generator_config_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mbackbone\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    311\u001b[39m     state_dict_prefix_func = filter_and_remove_prefix_state_dict_fn(\n\u001b[32m    312\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m_base_models.generator.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/omegaconf/omegaconf.py:189\u001b[39m, in \u001b[36mOmegaConf.load\u001b[39m\u001b[34m(file_)\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file_, (\u001b[38;5;28mstr\u001b[39m, pathlib.Path)):\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mabspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    190\u001b[39m         obj = yaml.load(f, Loader=get_yaml_loader())\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/dimi/Repositories/hoi/pretrained/sam3d/hf/ss_generator.yaml'",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mInstantiationException\u001b[39m                    Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m TAG = \u001b[33m\"\u001b[39m\u001b[33mhf\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m config_path = \u001b[33m'\u001b[39m\u001b[33m/home/dimi/Repositories/hoi/pretrained/sam3d/hf/pipeline.yaml\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m inference = \u001b[43mInference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/hoi/external/sam-3d-objects/notebook/inference.py:92\u001b[39m, in \u001b[36mInference.__init__\u001b[39m\u001b[34m(self, config_file, compile)\u001b[39m\n\u001b[32m     90\u001b[39m config.workspace_dir = os.path.dirname(config_file)\n\u001b[32m     91\u001b[39m check_hydra_safety(config, WHITELIST_FILTERS, BLACKLIST_FILTERS)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28mself\u001b[39m._pipeline: InferencePipelinePointMap = \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:226\u001b[39m, in \u001b[36minstantiate\u001b[39m\u001b[34m(config, *args, **kwargs)\u001b[39m\n\u001b[32m    223\u001b[39m     _convert_ = config.pop(_Keys.CONVERT, ConvertMode.NONE)\n\u001b[32m    224\u001b[39m     _partial_ = config.pop(_Keys.PARTIAL, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstantiate_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_recursive_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_convert_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_partial_\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m OmegaConf.is_list(config):\n\u001b[32m    230\u001b[39m     \u001b[38;5;66;03m# Finalize config (convert targets to strings, merge with kwargs)\u001b[39;00m\n\u001b[32m    231\u001b[39m     config_copy = copy.deepcopy(config)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:347\u001b[39m, in \u001b[36minstantiate_node\u001b[39m\u001b[34m(node, convert, recursive, partial, *args)\u001b[39m\n\u001b[32m    342\u001b[39m                 value = instantiate_node(\n\u001b[32m    343\u001b[39m                     value, convert=convert, recursive=recursive\n\u001b[32m    344\u001b[39m                 )\n\u001b[32m    345\u001b[39m             kwargs[key] = _convert_node(value, convert)\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_target_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    349\u001b[39m     \u001b[38;5;66;03m# If ALL or PARTIAL non structured or OBJECT non structured,\u001b[39;00m\n\u001b[32m    350\u001b[39m     \u001b[38;5;66;03m# instantiate in dict and resolve interpolations eagerly.\u001b[39;00m\n\u001b[32m    351\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert == ConvertMode.ALL \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m    352\u001b[39m         convert \u001b[38;5;129;01min\u001b[39;00m (ConvertMode.PARTIAL, ConvertMode.OBJECT)\n\u001b[32m    353\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m node._metadata.object_type \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m    354\u001b[39m     ):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32m~/mambaforge/envs/sam3d-objects/lib/python3.11/site-packages/hydra/_internal/instantiate/_instantiate2.py:97\u001b[39m, in \u001b[36m_call_target\u001b[39m\u001b[34m(_target_, _partial_, args, kwargs, full_key)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_key:\n\u001b[32m     96\u001b[39m     msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mfull_key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
                        "\u001b[31mInstantiationException\u001b[39m: Error in call to target 'sam3d_objects.pipeline.inference_pipeline_pointmap.InferencePipelinePointMap':\nFileNotFoundError(2, 'No such file or directory')"
                    ]
                }
            ],
            "source": [
                "PATH = os.getcwd()\n",
                "TAG = \"hf\"\n",
                "config_path = '/home/dimi/Repositories/hoi/pretrained/sam3d/hf/pipeline.yaml'\n",
                "inference = Inference(config_path, compile=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load input image to lift to 3D (single object)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "IMAGE_PATH = f\"{PATH}/images/shutterstock_stylish_kidsroom_1640806567/image.png\"\n",
                "IMAGE_NAME = os.path.basename(os.path.dirname(IMAGE_PATH))\n",
                "\n",
                "image = load_image(IMAGE_PATH)\n",
                "mask = load_single_mask(os.path.dirname(IMAGE_PATH), index=14)\n",
                "display_image(image, masks=[mask])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Gaussian Splat"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# run model\n",
                "output = inference(image, mask, seed=42)\n",
                "\n",
                "# export gaussian splat (as point cloud)\n",
                "output[\"gs\"].save_ply(f\"{PATH}/gaussians/single/{IMAGE_NAME}.ply\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualize Gaussian Splat\n",
                "### a. Animated Gif"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# render gaussian splat\n",
                "scene_gs = make_scene(output)\n",
                "scene_gs = ready_gaussian_for_video_rendering(scene_gs)\n",
                "\n",
                "video = render_video(\n",
                "    scene_gs,\n",
                "    r=1,\n",
                "    fov=60,\n",
                "    pitch_deg=15,\n",
                "    yaw_start_deg=-45,\n",
                "    resolution=512,\n",
                ")[\"color\"]\n",
                "\n",
                "# save video as gif\n",
                "imageio.mimsave(\n",
                "    os.path.join(f\"{PATH}/gaussians/single/{IMAGE_NAME}.gif\"),\n",
                "    video,\n",
                "    format=\"GIF\",\n",
                "    duration=1000 / 30,  # default assuming 30fps from the input MP4\n",
                "    loop=0,  # 0 means loop indefinitely\n",
                ")\n",
                "\n",
                "# notebook display\n",
                "ImageDisplay(url=f\"gaussians/single/{IMAGE_NAME}.gif?cache_invalidator={uuid.uuid4()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### b. Interactive Visualizer"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# might take a while to load (black screen)\n",
                "interactive_visualizer(f\"{PATH}/gaussians/single/{IMAGE_NAME}.ply\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "sam3d-objects",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
